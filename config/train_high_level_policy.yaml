data:
    algo: "hilp"
    data_town: ["Town01", "Town04", "Town06"]
    type: ["short"]
    num_workers: 4
    pin_memory: false
    train_batch_size: 512
    val_batch_size: 512
    val_ratio: 0.2
    trajectory_length: 10

model:
    action_dim: 3
    latent_dim: 10
    latent_as_action: true
    q_hidden_dim: 512
    v_hidden_dim: 512
    obs_feature_dim: 128
    hidden_dim: 256
    output_dim: 10

train:
    hilp_dir: "2025_11_19/11_30_09"
    hilp_dict_name: "epoch_0045_loss_0.064"
    device: "cuda:0"
    use_amp: true
    seed: 42
    num_epochs: 50
    eval_frequency: 5
    target_update_frequency: 1
    log_frequency: 100
    save_latest_ckpt: true
    patience: 5
    q_lr: 3e-4
    v_lr: 3e-4
    policy_lr: 1e-4
    tau: 0.9
    beta: 0.5
    discount: 0.99
    alpha: 0.005
    temperature: 1.0
    cql_alpha: 1.0
    z_high: 1.0
    z_low: -1.0

debug: false
resume: false
resume_ckpt_dir: ""
wb: true
wandb_project: "hilp"
wandb_name: "high_level"
wandb_tag: ["high-level-policy"]