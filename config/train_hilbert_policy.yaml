data:
    data_town: ["Town01", "Town04", "Town06"]
    type: ["short"]
    num_workers: 4
    pin_memory: false
    train_batch_size: 128
    val_batch_size: 64
    val_ratio: 0.2
    length: 10

model:
    latent_dim: 10
    action_dim: 3
    latent_as_action: false
    obs_feature_dim: 128
    condition_dim: 10
    hidden_dim: 256
    output_dim: 3
    q_hidden_dim: 256
    v_hidden_dim: 256

train:
    hilp_dir: "2025_11_19/11_30_09"
    hilp_dict_name: "epoch_0045_loss_0.064"
    device: "cuda:0"
    seed: 42
    num_epochs: 100
    eval_frequency: 5          # epochs
    log_frequency: 100          # steps
    target_update_frequency: 1
    use_amp: true
    save_latest_ckpt: true
    patience: 5
    q_lr: 3e-4
    v_lr: 3e-4
    policy_lr: 1e-4
    tau: 0.7
    skill_discount: 0.99
    skill_temperature: 0.5
    alpha: 0.005
    num_random: 10
    temperature: 1.0
    cql_alpha: 1.0
    z_high: 1.0
    z_low: -1.0

resume: true
resume_ckpt_dir: 2025_11_20/18_15_55
wb: true
wandb_project: "hilp"
wandb_name: "hilbert_policy"
wandb_tag: ["low-level-policy"]
